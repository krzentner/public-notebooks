{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Search to Differentiable First-Order Planning\n",
    "This is a notebook describing some of my thoughts on how to take a classic Artifical Intelligence planning technique and how to augment it using continuous representations. The resulting design will allow us to backpropagate through a significant portion of the planner.\n",
    "\n",
    "For this article, we'll be considering the example of a robot operating in a typical supermarket.\n",
    "\n",
    "We can model a store like that as a fixed number of locations (aisles, front segments, and back segments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "A = 5\n",
    "aisles = [f'Aisle{a}' for a in range(A)]\n",
    "front = [f'Front{s}' for s in range(A)]\n",
    "back = [f'Back{s}' for s in range(A)]\n",
    "adjacent = (frozenset(zip(aisles, front))\n",
    "            .union(zip(aisles, back))\n",
    "            .union((front[i], front[i+1]) for i in range(len(front) - 1))\n",
    "            .union((back[i], back[i+1]) for i in range(len(back) - 1)))\n",
    "adjacent = adjacent.union((e, s) for s, e in adjacent)\n",
    "#pprint(adjacent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to plan in such an environment, we could implement a simple fixed-depth tree search as follows. It uses depth-first search with early termination, and represents plans as sequences of states. For practical purposes, we could use a wide variety of more efficient search methods (MCTS, A*, etc.). However, the focus of this post isn't the search method, but the state transition function, `step`. For any search method there is an analogous function, so coming up with alternative formulations of the function is relevant to all search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 589 states\n",
      "26 total plans\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Aisle0', 'Back0', 'Aisle0', 'Back0', 'Back1', 'Back2', 'Back3', 'Aisle3')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(state, max_len):\n",
    "    successful_plans = []\n",
    "    global visit_count\n",
    "    visit_count = 0\n",
    "    all_plans = list(plans(state, max_len))\n",
    "    print('visited', visit_count, 'states')\n",
    "    print(len(all_plans), 'total plans')\n",
    "    return all_plans\n",
    "\n",
    "visit_count = 0\n",
    "\n",
    "def plans(state, max_len):\n",
    "    global visit_count\n",
    "    visit_count += 1\n",
    "    if goal(state):\n",
    "        yield (state,)\n",
    "    if max_len > 0:\n",
    "        for tails in step(state, max_len - 1):\n",
    "            for tail in tails:\n",
    "                yield (state,) + tail\n",
    "\n",
    "def step(state, max_len):\n",
    "    return (plans(e, max_len) for (s, e) in adjacent\n",
    "            if s == state)\n",
    "\n",
    "def goal(state):\n",
    "    return state == aisles[3]\n",
    "\n",
    "search(aisles[0], 7)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem that the `step` function has a relatively small role, and can't affect performance. However, since it can control what gets expanded, it actually can.\n",
    "\n",
    "For example, a small improvement which prevents needless backtracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 61 states\n",
      "6 total plans\n"
     ]
    }
   ],
   "source": [
    "def step(state, max_len):\n",
    "    last_act, loc = state\n",
    "    return (plans((('Move', s, e), e), max_len)\n",
    "            for s, e in adjacent\n",
    "            if s == loc\n",
    "                and last_act != ('Move', e, s) # Don't allow moving backwards.\n",
    "           )\n",
    "\n",
    "def goal(state):\n",
    "    return state[-1] == aisles[3]\n",
    "\n",
    "search(('Start', aisles[0]), 7); # Remove the semicolon to see the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partly, this method does well because the branching factor is very small. If we were managing multiple robots, that would make the branching factor much higher, and the search method less efficient.\n",
    "\n",
    "Here's how we might model that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 910311 states\n",
      "8260 total plans\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def update_state(state, to_add):\n",
    "    state = state.copy()\n",
    "    state.update(to_add)\n",
    "    return state\n",
    "\n",
    "R = 8\n",
    "robots = list(range(R))\n",
    "def step(state, max_len):\n",
    "    p = lambda a: update_state(state, a)\n",
    "    return (plans(p({('last_act', rob): ('Move', s, e), ('loc', rob): e}), max_len)\n",
    "            for rob in robots\n",
    "            for s, e in adjacent\n",
    "            if state[('loc', rob)] == s and state[('last_act', rob)] != ('Move', e, s))\n",
    "\n",
    "def goal(state):\n",
    "    return any(state[('loc', r)] == aisles[3] for r in robots)\n",
    "start_state = defaultdict(tuple, {('loc', r): aisles[r % 3] for r in robots})\n",
    "\n",
    "search(start_state, 5); # Remove the semicolon to see the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the method works much worse with a higher branching factor. Fortunately, finding one plan can still be done quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 260 states\n"
     ]
    }
   ],
   "source": [
    "def sample(state, max_len):\n",
    "    global visit_count\n",
    "    visit_count = 0\n",
    "    try:\n",
    "        result = next(plans(state, max_len))\n",
    "    except StopIteration:\n",
    "        result = None\n",
    "    print('visited', visit_count, 'states')\n",
    "    return result\n",
    "sample(start_state, 5); # Remove the semicolon to see the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be taking single plans (or \"sampling\") from now on to avoid waiting. In this case, we get a non-optimal plan. However, if we used a more advanced search method (e.g. branch-and-bound), we would have similar performance and get a near-optimal plan.\n",
    "\n",
    "We can also imagine modelling more complex environments, with more actions.\n",
    "Let's add some carts, which impede movement unless pushed to a destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 61495 states\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Aisle1',\n",
       "              ('loc', 2): 'Aisle2',\n",
       "              ('cart_loc', 0): 'Aisle3',\n",
       "              ('cart_loc', 1): 'Back3',\n",
       "              ('cart_loc', 2): 'Front3',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ()}),\n",
       " defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Back1',\n",
       "              ('loc', 2): 'Aisle2',\n",
       "              ('cart_loc', 0): 'Aisle3',\n",
       "              ('cart_loc', 1): 'Back3',\n",
       "              ('cart_loc', 2): 'Front3',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ('Move', 'Aisle1', 'Back1')}),\n",
       " defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Back2',\n",
       "              ('loc', 2): 'Aisle2',\n",
       "              ('cart_loc', 0): 'Aisle3',\n",
       "              ('cart_loc', 1): 'Back3',\n",
       "              ('cart_loc', 2): 'Front3',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ('Move', 'Back1', 'Back2'),\n",
       "              ('last_act', 2): ()}),\n",
       " defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Back2',\n",
       "              ('loc', 2): 'Front2',\n",
       "              ('cart_loc', 0): 'Aisle3',\n",
       "              ('cart_loc', 1): 'Back3',\n",
       "              ('cart_loc', 2): 'Front3',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ('Move', 'Back1', 'Back2'),\n",
       "              ('last_act', 2): ('Move', 'Aisle2', 'Front2')}),\n",
       " defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Back3',\n",
       "              ('loc', 2): 'Front2',\n",
       "              ('cart_loc', 0): 'Aisle3',\n",
       "              ('cart_loc', 1): 'Back4',\n",
       "              ('cart_loc', 2): 'Front3',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ('PushCart', 'Back3', 'Back4'),\n",
       "              ('last_act', 2): ('Move', 'Aisle2', 'Front2')}),\n",
       " defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Back2',\n",
       "              ('loc', 2): 'Front2',\n",
       "              ('cart_loc', 0): 'Aisle3',\n",
       "              ('cart_loc', 1): 'Back4',\n",
       "              ('cart_loc', 2): 'Front3',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ('Move', 'Back3', 'Back2'),\n",
       "              ('last_act', 2): ('Move', 'Aisle2', 'Front2')}),\n",
       " defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Back2',\n",
       "              ('loc', 2): 'Front3',\n",
       "              ('cart_loc', 0): 'Aisle3',\n",
       "              ('cart_loc', 1): 'Back4',\n",
       "              ('cart_loc', 2): 'Front4',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ('Move', 'Back3', 'Back2'),\n",
       "              ('last_act', 2): ('PushCart', 'Front3', 'Front4')}),\n",
       " defaultdict(tuple,\n",
       "             {('loc', 0): 'Aisle0',\n",
       "              ('loc', 1): 'Back2',\n",
       "              ('loc', 2): 'Aisle3',\n",
       "              ('cart_loc', 0): 'Back3',\n",
       "              ('cart_loc', 1): 'Back4',\n",
       "              ('cart_loc', 2): 'Front4',\n",
       "              ('last_act', 0): (),\n",
       "              ('last_act', 1): ('Move', 'Back3', 'Back2'),\n",
       "              ('last_act', 2): ('PushCart', 'Aisle3', 'Back3')}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step(state, max_len):\n",
    "    p = lambda a: update_state(state, a)\n",
    "    yield from (plans(p({('last_act', rob): ('Move', s, e), ('loc', rob): e}), max_len)\n",
    "             for rob in robots\n",
    "             for s, e in adjacent\n",
    "             if state[('loc', rob)] == s\n",
    "                and state[('last_act', rob)] != ('Move', e, s)\n",
    "                and not any(state[('cart_loc', c)] == e for c in carts))\n",
    "    yield from (plans(p({('last_act', rob): ('PushCart', e1, e2),\n",
    "                      ('loc', rob): e1,\n",
    "                      ('cart_loc', c1): e2}), max_len)\n",
    "             for rob in robots\n",
    "             for s1, e1 in adjacent\n",
    "             for s2, e2 in adjacent\n",
    "             for c1 in carts\n",
    "             if state[('loc', rob)] == s1\n",
    "                and state[('cart_loc', c1)] == e1\n",
    "                and e1 == s2\n",
    "                and s1 != e2\n",
    "                and not any(state[('loc', r2)] == e2 for r2 in robots)\n",
    "                and not any(state[('cart_loc', c2)] == e2 for c2 in carts))\n",
    "\n",
    "robots = [0, 1, 2]\n",
    "carts = [0, 1, 2]\n",
    "cart_start_state = defaultdict(tuple,\n",
    "                               {('loc', 0): aisles[0],\n",
    "                                ('loc', 1): aisles[1],\n",
    "                                ('loc', 2): aisles[2],\n",
    "                                ('cart_loc', 0): aisles[3],\n",
    "                                ('cart_loc', 1): back[3],\n",
    "                                ('cart_loc', 2): front[3]\n",
    "                               })\n",
    "sample(cart_start_state, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has some neat properties. The robots automatically \"collaborate,\" since the planner can reason about all of them.\n",
    "\n",
    "However, unless your computer is extremely fast, you probably noticed a delay to sample a single plan. Adding additional robots would make this even worse. Noticeably, the number of states we're visiting is still small (around 60000) compared to what we were looking at before (910311). `step` has become much more expensive to compute.\n",
    "\n",
    "`step` has also gotten rather large, even though it has a regular structure.\n",
    "\n",
    "This particular regular structure is easy to translate into a set of logic clauses (what a coincidence!).\n",
    "Not only would this allow expressing our actions more succinctly, it would allow some very non-obvious optimizations.\n",
    "For example, avoiding impossible parts of the search space, searching \"backwards\" from all goal states, searching abstractly over all robots' actions at once, etc. We could even specify heuristics in the same relational language, making all of these optimizations more effective.\n",
    "\n",
    "A very simple optimization this allows is using hash-joins in place of our naive outer joins (the nested `for` loops). We'll implement that below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last `step` function above could be expressed in an extended Prolog / Datalog syntax as:\n",
    "```prolog\n",
    "-last_act(R, _, _, _), last_act(R, \"move\", S, E), -loc(R, _), loc(R, E) :-\n",
    "    loc(R, S),\n",
    "    adjacent(S, E),\n",
    "    -last_act(R, \"move\", E, S),\n",
    "    -cart_loc(C, E)\n",
    "\n",
    "-last_act(R, _, _, _), last_act(R, \"push_cart\", E1, E2), -loc(R, _), loc(R, E1),\n",
    "        -cart_loc(C, _), cart_loc(C, E2) :-\n",
    "    loc(R, L),\n",
    "    adjacent(L, E1),\n",
    "    adjacent(E1, E2),\n",
    "    L != E2,\n",
    "    cart_loc(C, E1),\n",
    "    -loc(R2, E2),\n",
    "    -cart_loc(C2, E2)\n",
    "```\n",
    "This syntax is not ideal for this application, but is the most common syntax for logic programming. For more commonly used syntaxes for planning specifically, I recommend reading about [STRIPS](https://en.wikipedia.org/wiki/STRIPS#A_sample_STRIPS_problem), [Action Description Language](https://en.wikipedia.org/wiki/Action_description_language#Example), or [Planning Domain Definition Language](https://en.wikipedia.org/wiki/Planning_Domain_Definition_Language#Example).\n",
    "In this syntax, the effects are on the left of the implication sign (`:-`), all positive atoms (e.g. `loc(R, L)` or `L != E2`) to the right of the implication sign must be true, all negative atoms (e.g. `-loc(R2, E2)`) must not be true for any values of the atom's unique variables, and all repeated uses of variables are implicit equality constraints.\n",
    "\n",
    "Below is how an extremely simple Datalog frontend would have compiled our step function into backend operations defined further below. It isn't necessary to understand these functions in detail. Essentially, each clause is its own subfunction, where all constraints are enforced using joins. Then, effects are generated by iterating over all of the rows.\n",
    "\n",
    "I've commented each line with what constraint each line is enforcing, the resulting layout of the temporary table (if it changed), and each effect (when relevant).\n",
    "\n",
    "I've also randomized the order of the next states. The hash function makes the search order non-deterministic, so we may as well make it fully random. This wasn't easy to do with the previous definition of the step function, since we never built a representation of \"all next states.\" However, this is still depth-first search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, max_len):\n",
    "    yield from step_move(state, max_len)\n",
    "    yield from step_push(state, max_len)\n",
    "\n",
    "def step_move(state, max_len):\n",
    "    t = outer_eq_join(gen_index(state['loc'], 1), fixed['adj'][0]) # L == S: R,L,S,E\n",
    "    t = outer_eq_join(gen_index(t, 0), gen_index(state['last_act'], 0)) # R == Q: R,L,S,E,Q,A,T,Y\n",
    "    t = constant(t, 'move') # R,L,S,E,Q,A,T,Y,\"move\"\n",
    "    t = filter_ne(t, (3, 5), (7, 8))  # E != Y || A != \"move\"\n",
    "    t = left_eq_ajoin(gen_index(t, 3), gen_index(state['cart_loc'], 1)) # E == no D\n",
    "    shuffle_table(t)\n",
    "    for row in t:\n",
    "        new_state = state.copy()\n",
    "        # -last_act(R, _, _, _)\n",
    "        new_state['last_act'] = filter_eq_key(new_state['last_act'], row, 0, 0)\n",
    "        append_row(new_state['last_act'], row, (0, 8, 2, 3)) # last_act(R, \"move\", S, E)\n",
    "        new_state['loc'] = filter_eq_key(new_state['loc'], row, 0, 0) # -loc(R, _)\n",
    "        append_row(new_state['loc'], row, (0, 3)) # loc(R, E)\n",
    "        yield plans(new_state, max_len)\n",
    "\n",
    "def step_push(state, max_len):\n",
    "    t = outer_eq_join(gen_index(state['loc'], 1), fixed['adj'][0]) # L == S: R,L,S,E\n",
    "    t = outer_eq_join(gen_index(t, 3), gen_index(state['cart_loc'], 1)) # E == D: R,L,S,E,C,D\n",
    "    t = outer_eq_join(gen_index(t, 3), fixed['adj'][0]) # E1 == S2: R,L,S1,E1,C,D,S2,E2\n",
    "    t = filter_ne(t, (2,), (7,)) # S1 != E2\n",
    "    t = left_eq_ajoin(gen_index(t, 7), gen_index(state['loc'], 1)) # E2 == no L2\n",
    "    t = left_eq_ajoin(gen_index(t, 7), gen_index(state['cart_loc'], 1)) # E2 == no D2\n",
    "    t = constant(t, 'push') # R,L,S1,E1,C,D,S2,E2,\"move\"\n",
    "    shuffle_table(t)\n",
    "    for row in t:\n",
    "        new_state = state.copy()\n",
    "        # -last_act(R, _, _, _)\n",
    "        new_state['last_act'] = filter_eq_key(new_state['last_act'], row, 0, 0)\n",
    "        append_row(new_state['last_act'], row, (0, 8, 3, 7)) # last_act(R, \"push_cart\", E1, E2)\n",
    "        new_state['loc'] = filter_eq_key(new_state['loc'], row, 0, 0) # -loc(R, _)\n",
    "        append_row(new_state['loc'], row, (0, 3)) # loc(R, E1)\n",
    "        new_state['cart_loc'] = filter_eq_key(new_state['cart_loc'], row, 0, 4) # -cart_loc(C, _)\n",
    "        append_row(new_state['cart_loc'], row, (4, 7)) # cart_loc(C, E2)\n",
    "        yield plans(new_state, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is how this backend works. It's extremely simple, using [hash-joins](https://en.wikipedia.org/wiki/Hash_join) to impose all constraints, and searching forwards (from the start state). In this implementation, \"databases\" (which are equivalent to states in our search process), are `dict`s mapping from `str`s to \"tables.\" Tables in are `list`s of \"rows.\" Rows in turn are `list`s of \"symbols\" (`int`s or `str`s). Of particular note, is that the implementation works by creating temporary \"indices\", which are `dict`s mapping from a specific column's value to each row where the specified column had that value.\n",
    "\n",
    "For example, a start state in this implementation looks like this:\n",
    "```python\n",
    "{'cart_loc': [(0, 'Aisle3'), (1, 'Front3'), (2, 'Back3')],\n",
    " 'last_act': [(0, 'start', None, None),\n",
    "              (1, 'start', None, None),\n",
    "              (2, 'start', None, None)],\n",
    " 'loc': [(0, 'Aisle0'), (1, 'Aisle1'), (2, 'Aisle2')]}\n",
    "```\n",
    "\n",
    "An index over the `1` column of the `loc` table would look like this:\n",
    "```python\n",
    "{'Aisle0': [(0, 'Aisle0')],\n",
    " 'Aisle1': [(1, 'Aisle1')],\n",
    " 'Aisle2': [(2, 'Aisle2')]}\n",
    "```\n",
    "\n",
    "And an index over the `0` column of the `adj` table would look like this:\n",
    "```python\n",
    "{'Aisle0': [('Aisle0', 'Front0'), ('Aisle0', 'Back0')],\n",
    " 'Aisle1': [('Aisle1', 'Back1'), ('Aisle1', 'Front1')],\n",
    " 'Aisle2': [('Aisle2', 'Front2'), ('Aisle2', 'Back2')],\n",
    " 'Aisle3': [('Aisle3', 'Back3'), ('Aisle3', 'Front3')],\n",
    " 'Aisle4': [('Aisle4', 'Front4'), ('Aisle4', 'Back4')],\n",
    " 'Back0': [('Back0', 'Aisle0'), ('Back0', 'Back1')],\n",
    " 'Back1': [('Back1', 'Back2'), ('Back1', 'Aisle1'), ('Back1', 'Back0')],\n",
    " 'Back2': [('Back2', 'Back3'), ('Back2', 'Aisle2'), ('Back2', 'Back1')],\n",
    " 'Back3': [('Back3', 'Back2'), ('Back3', 'Aisle3'), ('Back3', 'Back4')],\n",
    " 'Back4': [('Back4', 'Back3'), ('Back4', 'Aisle4')],\n",
    " 'Front0': [('Front0', 'Aisle0'), ('Front0', 'Front1')],\n",
    " 'Front1': [('Front1', 'Aisle1'), ('Front1', 'Front0'), ('Front1', 'Front2')],\n",
    " 'Front2': [('Front2', 'Front3'), ('Front2', 'Front1'), ('Front2', 'Aisle2')],\n",
    " 'Front3': [('Front3', 'Front2'), ('Front3', 'Front4'), ('Front3', 'Aisle3')],\n",
    " 'Front4': [('Front4', 'Aisle4'), ('Front4', 'Front3')]}\n",
    "```\n",
    "\n",
    "We could then compute all the places all robots can move by performing an outer join between these two indices. The result would be a new table, which (in this case) shows that each robot can move to the front or back of its current aisle.\n",
    "```python\n",
    "[(0, 'Aisle0', 'Aisle0', 'Front0'),\n",
    " (0, 'Aisle0', 'Aisle0', 'Back0'),\n",
    " (1, 'Aisle1', 'Aisle1', 'Back1'),\n",
    " (1, 'Aisle1', 'Aisle1', 'Front1'),\n",
    " (2, 'Aisle2', 'Aisle2', 'Front2'),\n",
    " (2, 'Aisle2', 'Aisle2', 'Back2')]\n",
    "```\n",
    "\n",
    "The advantage of this method over a naive join is that it is linear time in all inputs (and the output). For large tables (such as the adjacency table), this is more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def gen_index(table, i):\n",
    "    '''Create a \"hash index\" from a table (a list of rows (which are also lists)).'''\n",
    "    index = {}\n",
    "    for row in table:\n",
    "        index.setdefault(row[i], []).append(row)\n",
    "    return index\n",
    "\n",
    "def outer_eq_join(a, b):\n",
    "    '''Given two hash indices, compute the union where the indices are equal.'''\n",
    "    if len(a) <= len(b):\n",
    "        return [a_v + b_v for k, v in a.items()\n",
    "                for a_v in v\n",
    "                for b_v in b.get(k, ())]\n",
    "    else:\n",
    "        return [a_v + b_v for k, v in b.items()\n",
    "                for b_v in v\n",
    "                for a_v in a.get(k, ())]\n",
    "\n",
    "def left_eq_ajoin(a, b):\n",
    "    '''Given two hash indices, compute the rows of the left index not in the right index.'''\n",
    "    return [a_v for k, v in a.items()\n",
    "            for a_v in v\n",
    "            if k not in b]\n",
    "\n",
    "def filter_ne(table, ix, jx):\n",
    "    '''Given a table, remove all rows where any of a pair of columns are equal.'''\n",
    "    return [row for row in table if any((row[i] != row[j] for i,j in zip(ix, jx)))]\n",
    "\n",
    "def constant(table, c):\n",
    "    '''Add a constant to each row of the table.'''\n",
    "    return [row + (c,) for row in table]\n",
    "\n",
    "def filter_eq_key(table, key_row, column, key):\n",
    "    '''Given a table, remove all rows where a column has a specific key.'''\n",
    "    return [row for row in table if row[column] != key_row[key]]\n",
    "\n",
    "def append_row(table, row, columns):\n",
    "    table.append(tuple([row[c] for c in columns]))\n",
    "\n",
    "def gen_fixed():\n",
    "    '''Generate indices for all the fixed tables (just the adjacency table).'''\n",
    "    adj_list = list(adjacent)\n",
    "    return {'adj': [gen_index(adj_list, i) for i in (0, 1)]}\n",
    "\n",
    "def gen_start():\n",
    "    '''Generate a database representing the start state.'''\n",
    "    loc_tables = list(enumerate(robot_locations))\n",
    "    cart_loc_tables = list(enumerate(cart_locations))\n",
    "    return {\n",
    "        'loc': loc_tables, \n",
    "        'cart_loc': cart_loc_tables, \n",
    "        'last_act': [(r, 'start', None, None) for r in range(len(robot_locations))],\n",
    "    }\n",
    "\n",
    "def shuffle_table(table):\n",
    "    random.shuffle(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, here's that implementation in action. Note that the number of states searched ranges from around 10000 to 200000. If we were to use heuristics, we could keep this on the lower side of that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 78055 states\n",
      "({'cart_loc': [(0, 'Aisle3'), (1, 'Front3'), (2, 'Back3')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (1, 'start', None, None),\n",
      "               (2, 'start', None, None)],\n",
      "  'loc': [(0, 'Aisle0'), (1, 'Aisle1'), (2, 'Aisle2')]},\n",
      " {'cart_loc': [(0, 'Aisle3'), (1, 'Front3'), (2, 'Back3')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (2, 'start', None, None),\n",
      "               (1, 'move', 'Aisle1', 'Front1')],\n",
      "  'loc': [(0, 'Aisle0'), (2, 'Aisle2'), (1, 'Front1')]},\n",
      " {'cart_loc': [(0, 'Aisle3'), (1, 'Front3'), (2, 'Back3')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (2, 'start', None, None),\n",
      "               (1, 'move', 'Front1', 'Front2')],\n",
      "  'loc': [(0, 'Aisle0'), (2, 'Aisle2'), (1, 'Front2')]},\n",
      " {'cart_loc': [(0, 'Aisle3'), (1, 'Front3'), (2, 'Back3')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (1, 'move', 'Front1', 'Front2'),\n",
      "               (2, 'move', 'Aisle2', 'Back2')],\n",
      "  'loc': [(0, 'Aisle0'), (1, 'Front2'), (2, 'Back2')]},\n",
      " {'cart_loc': [(0, 'Aisle3'), (1, 'Front3'), (2, 'Back4')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (1, 'move', 'Front1', 'Front2'),\n",
      "               (2, 'push', 'Back3', 'Back4')],\n",
      "  'loc': [(0, 'Aisle0'), (1, 'Front2'), (2, 'Back3')]},\n",
      " {'cart_loc': [(0, 'Aisle3'), (1, 'Front3'), (2, 'Back4')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (1, 'move', 'Front1', 'Front2'),\n",
      "               (2, 'move', 'Back3', 'Back2')],\n",
      "  'loc': [(0, 'Aisle0'), (1, 'Front2'), (2, 'Back2')]},\n",
      " {'cart_loc': [(0, 'Aisle3'), (2, 'Back4'), (1, 'Front4')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (2, 'move', 'Back3', 'Back2'),\n",
      "               (1, 'push', 'Front3', 'Front4')],\n",
      "  'loc': [(0, 'Aisle0'), (2, 'Back2'), (1, 'Front3')]},\n",
      " {'cart_loc': [(2, 'Back4'), (1, 'Front4'), (0, 'Back3')],\n",
      "  'last_act': [(0, 'start', None, None),\n",
      "               (2, 'move', 'Back3', 'Back2'),\n",
      "               (1, 'push', 'Aisle3', 'Back3')],\n",
      "  'loc': [(0, 'Aisle0'), (2, 'Back2'), (1, 'Aisle3')]})\n"
     ]
    }
   ],
   "source": [
    "robot_locations = [aisles[0], aisles[1], aisles[2]]\n",
    "cart_locations = [aisles[3], front[3], back[3]]\n",
    "fixed = gen_fixed()\n",
    "start = gen_start()\n",
    "def goal(state):\n",
    "    return any((r, aisles[3]) in state['loc'] for r in robots)\n",
    "pprint(sample(start, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, everything I've described is well understood. However, it operates under the assumption that our state space is discrete. In particular, our robot locations are either a specific aisle, back, or front. Typically, if we wanted to apply this method to a continuous space, we would discretize the space into a set of cells, maintain weights for each cell, apply our rules as usual over the cells, and add some noise. However, I would like to propose a different method: define the logic over continuous values instead.\n",
    "\n",
    "Instead of our \"symbols\" being `int`s or `str`s (which could represent robots, locations, carts, or grid cells), our \"symbols\" will be vectors in a continous space. Instead of using exact equality to compare these \"symbols\", we will use a similarity measure. A similar approach was taken for query answering in [End-to-End Differentiable Proving](https://arxiv.org/abs/1705.11040)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def similarity(key1, key2, sigma=.25):\n",
    "    '''Measures key similarity, returning 1 for identical keys and 0 for infinitely distant keys.'''\n",
    "    return torch.exp(-((key1 - key2) ** 2).sum() / sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our continuous vectors can't be hashed, we could use [locality sensitive hashing](https://en.wikipedia.org/wiki/Locality-sensitive_hashing#Stable_distributions) in place of a `dict`. That is implemented below, but the rest of the notebook uses \"full lookup\", applying the similarity between the lookup key and every key in the index. This is much slower, but guarantees we don't miss any of the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalitySensitiveHashIndex:\n",
    "    \n",
    "    def __init__(self, table, i, num_hashes=32, num_buckets=4):\n",
    "        self.entries = defaultdict(list)\n",
    "        self.num_entries = 0\n",
    "        self.num_hashes = num_hashes\n",
    "        self.num_buckets = num_buckets\n",
    "        D = table[0][0][i].shape[0]\n",
    "        self.projections = torch.randn(num_hashes, D)\n",
    "        self.r = 0.5\n",
    "        self.bs = self.r * torch.rand(num_hashes)\n",
    "        for row, weight in table:\n",
    "            self.insert(row[i], row, weight)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in range(self.num_buckets):\n",
    "            yield from self.entries[(0, b)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_entries\n",
    "\n",
    "    def hash_key(self, v):\n",
    "        projected = self.projections.matmul(v)\n",
    "        offset = projected + self.bs\n",
    "        return (offset / self.r).floor() % self.num_buckets\n",
    "\n",
    "    def insert(self, key, row, weight):\n",
    "        hs = self.hash_key(key)\n",
    "        self.num_entries += 1\n",
    "        for ih, h in enumerate(hs):\n",
    "            self.entries[(ih, int(h.item()))].append((key, row, weight))\n",
    "\n",
    "    def sample_lookups(self, key, n=8):\n",
    "        '''Samples a random lookup given the key, returning a list of rows and weights.\n",
    "        \n",
    "        This method isn't actually used in this notebook, but illustrates how\n",
    "        locality sensitive hashing can accelerate lookup (with some caveats).\n",
    "        '''\n",
    "        result = []\n",
    "        for i in range(n):\n",
    "            hs = self.hash_key(key)\n",
    "            ih = random.randrange(len(hs))\n",
    "            h = hs[ih].item()\n",
    "            entries = self.entries[(ih, h)]\n",
    "            if entries:\n",
    "                key2, value, weight = random.choice(entries)\n",
    "                result.append((key2, value, weight * similarity(key, key2)))\n",
    "        return result\n",
    "    \n",
    "    def full_lookup(self, key):\n",
    "        '''Looks up all entries given the key, returning a list of rows and weights.'''\n",
    "        for key2, value, weight in self:\n",
    "            yield (key2, value, weight * similarity(key, key2))\n",
    "    \n",
    "    def best_lookup(self, key):\n",
    "        '''Finds the row with highest lookup weight using key, returning a row and weight.'''\n",
    "        hs = self.hash_key(key)\n",
    "        best_row = None\n",
    "        best_weight = 0.0\n",
    "        for ih, h in enumerate(hs):\n",
    "            for row_key, row, weight in self.entries[(ih, h.item())]:\n",
    "                w = weight * similarity(key, row_key)\n",
    "                if w > best_weight:\n",
    "                    best_row = row\n",
    "                    best_weight = w\n",
    "        return best_row, best_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then replace \"the backend\", so that our step function (which we \"compiled\" from first-order logic), can run un-modified. This mostly involves replacing our \"hash indices\" with the `LocalitySensitiveHashIndex` defined above, and replacing equality comparison with thresholding on our similarity measure. Note that in a more fully developed implementation, we would likely want to learn the parameters of the similarity measure, and an appropriate cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_index(table, i):\n",
    "    if len(table) > 0:\n",
    "        return LocalitySensitiveHashIndex(table, i)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Similarities below this are considered irrelevant.\n",
    "EQ_CUTOFF = 0.5\n",
    "\n",
    "def outer_eq_join(a, b):\n",
    "    '''Given two hash indices, compute the union where the indices are equal.'''\n",
    "    if a is None or b is None:\n",
    "        return []\n",
    "    if len(a) <= len(b):\n",
    "        return [(a_v + b_v, a_w * b_w)\n",
    "                for a_k, a_v, a_w in a\n",
    "                for b_k, b_v, b_w in b.full_lookup(a_k)\n",
    "                if similarity(a_k, b_k) > EQ_CUTOFF]\n",
    "    else:\n",
    "        return [(a_v + b_v, a_w * b_w)\n",
    "                for b_k, b_v, b_w in b\n",
    "                for a_k, a_v, a_w in a.full_lookup(b_k)\n",
    "                if similarity(a_k, b_k) > EQ_CUTOFF]\n",
    "\n",
    "def left_eq_ajoin(a, b):\n",
    "    '''Given two hash indices, compute the rows of the left index not in the right index.'''\n",
    "    if a is None:\n",
    "        return []\n",
    "    if b is None:\n",
    "        return [(a_v, a_w) for k_a, a_v, a_w in a]\n",
    "    return [(a_v, a_w * (1 - b.best_lookup(k_a)[1])) for k_a, a_v, a_w in a]\n",
    "\n",
    "def filter_ne(table, ix, jx):\n",
    "    '''Given a table, remove all rows where any of a pair of columns are equal.'''\n",
    "    return [(row, w) for row, w in table\n",
    "            if any((similarity(row[i], row[j]) < EQ_CUTOFF for i,j in zip(ix, jx)))]\n",
    "\n",
    "def filter_eq_key(table, key_row, column, key):\n",
    "    '''Given a table, remove all rows where a column has a specific key.'''\n",
    "    return [row for row in table if similarity(row[0][column], key_row[0][key]) < EQ_CUTOFF]\n",
    "\n",
    "def append_row(table, row, columns):\n",
    "    row, weight = row\n",
    "    table.append((tuple([row[c] for c in columns]), weight))\n",
    "\n",
    "# In a real implementation, we would probably support non-vectors in the backend.\n",
    "CONSTANT_VECTORS = {\n",
    "    'start': torch.tensor([0.0, 0.0, 0.0]),\n",
    "    'move': torch.tensor([1.0, 1.0, 1.0]),\n",
    "    'push': torch.tensor([2.0, 2.0, 2.0]),\n",
    "}\n",
    "\n",
    "def constant(table, c):\n",
    "    '''Add a constant to each row of the table.'''\n",
    "    return [(row + (CONSTANT_VECTORS[c],), w) for row, w in table]\n",
    "\n",
    "WEIGHT_CUTOFF = 0.15\n",
    "\n",
    "def shuffle_table(table):\n",
    "    random.shuffle(table)\n",
    "    # Discard actions that are very unlikely to succeed.\n",
    "    table[:] = [(row, w) for row, w in table if w > WEIGHT_CUTOFF]\n",
    "\n",
    "aisles_t = [torch.tensor([i, 0.0]) for i in range(A)]\n",
    "back_t = [torch.tensor([i, -1.0]) for i in range(A)]\n",
    "front_t = [torch.tensor([i, 1.0]) for i in range(A)]\n",
    "\n",
    "def gen_fixed():\n",
    "    '''Generate indices for all the fixed tables (just the adjacency table).'''\n",
    "    adjacent = (list(zip(aisles_t, front_t)) +\n",
    "                list(zip(aisles_t, back_t)) +\n",
    "                [(front_t[i], front_t[i+1]) for i in range(len(front_t) - 1)] +\n",
    "                [(back_t[i], back_t[i+1]) for i in range(len(back_t) - 1)])\n",
    "    adjacent = adjacent + [(e, s) for s, e in adjacent]\n",
    "    adj_table = [(row, 1.0) for row in adjacent]\n",
    "    return {'adj': [gen_index(adj_table, i) for i in (0, 1)]}\n",
    "\n",
    "def gen_start():\n",
    "    '''Generate a database representing the start state.'''\n",
    "    loc_table = [((torch.tensor([float(rob)]), loc), 1.0)\n",
    "                 for rob, loc in enumerate(robot_locations)]\n",
    "    cart_loc_table = [((torch.tensor([float(cart)]), loc), 1.0)\n",
    "                      for cart, loc in enumerate(cart_locations)]\n",
    "    return {\n",
    "        'loc': loc_table, \n",
    "        'cart_loc': cart_loc_table, \n",
    "        'last_act': [((rob, CONSTANT_VECTORS['start'], loc, loc), 1.0)\n",
    "                     for (rob, loc), _ in loc_table],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then search with the same step function we defined before. Since there isn't any noise in the planning system, most vectors match exactly. However, since our similarity measure has infinite support, we still end up with weights less than 1 due to \"collisions\" with nearby objects. For example, moving next to a cart decreases the weight / confidence in that action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 3335 states\n",
      "({'cart_loc': [((tensor([0.]), tensor([3., 0.])), 1.0),\n",
      "               ((tensor([1.]), tensor([3., 1.])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3., -1.])), 1.0)],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([0., 0., 0.]),\n",
      "                 tensor([1., 0.]),\n",
      "                 tensor([1., 0.])),\n",
      "                1.0),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([0., 0., 0.]),\n",
      "                 tensor([2., 0.]),\n",
      "                 tensor([2., 0.])),\n",
      "                1.0)],\n",
      "  'loc': [((tensor([0.]), tensor([1., 0.])), 1.0),\n",
      "          ((tensor([1.]), tensor([2., 0.])), 1.0)]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3., 0.])), 1.0),\n",
      "               ((tensor([1.]), tensor([3., 1.])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3., -1.])), 1.0)],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([0., 0., 0.]),\n",
      "                 tensor([1., 0.]),\n",
      "                 tensor([1., 0.])),\n",
      "                1.0),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([2., 0.]),\n",
      "                 tensor([2., 1.])),\n",
      "                tensor(0.9817))],\n",
      "  'loc': [((tensor([0.]), tensor([1., 0.])), 1.0),\n",
      "          ((tensor([1.]), tensor([2., 1.])), tensor(0.9817))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3., 0.])), 1.0),\n",
      "               ((tensor([1.]), tensor([3., 1.])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3., -1.])), 1.0)],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([2., 0.]),\n",
      "                 tensor([2., 1.])),\n",
      "                tensor(0.9817)),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([1., 0.]),\n",
      "                 tensor([ 1., -1.])),\n",
      "                tensor(1.0000))],\n",
      "  'loc': [((tensor([1.]), tensor([2., 1.])), tensor(0.9817)),\n",
      "          ((tensor([0.]), tensor([ 1., -1.])), tensor(1.0000))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3., 0.])), 1.0),\n",
      "               ((tensor([1.]), tensor([3., 1.])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3., -1.])), 1.0)],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([2., 0.]),\n",
      "                 tensor([2., 1.])),\n",
      "                tensor(0.9817)),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([ 1., -1.]),\n",
      "                 tensor([ 2., -1.])),\n",
      "                tensor(0.9817))],\n",
      "  'loc': [((tensor([1.]), tensor([2., 1.])), tensor(0.9817)),\n",
      "          ((tensor([0.]), tensor([ 2., -1.])), tensor(0.9817))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3., 0.])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3., -1.])), 1.0),\n",
      "               ((tensor([1.]), tensor([4., 1.])), tensor(0.9637))],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([ 1., -1.]),\n",
      "                 tensor([ 2., -1.])),\n",
      "                tensor(0.9817)),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([2., 2., 2.]),\n",
      "                 tensor([3., 1.]),\n",
      "                 tensor([4., 1.])),\n",
      "                tensor(0.9637))],\n",
      "  'loc': [((tensor([0.]), tensor([ 2., -1.])), tensor(0.9817)),\n",
      "          ((tensor([1.]), tensor([3., 1.])), tensor(0.9637))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3., 0.])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3., -1.])), 1.0),\n",
      "               ((tensor([1.]), tensor([4., 1.])), tensor(0.9637))],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([ 1., -1.]),\n",
      "                 tensor([ 2., -1.])),\n",
      "                tensor(0.9817)),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([3., 1.]),\n",
      "                 tensor([2., 1.])),\n",
      "                tensor(0.9284))],\n",
      "  'loc': [((tensor([0.]), tensor([ 2., -1.])), tensor(0.9817)),\n",
      "          ((tensor([1.]), tensor([2., 1.])), tensor(0.9284))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3., 0.])), 1.0),\n",
      "               ((tensor([1.]), tensor([4., 1.])), tensor(0.9637)),\n",
      "               ((tensor([2.]), tensor([ 4., -1.])), tensor(0.9637))],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([3., 1.]),\n",
      "                 tensor([2., 1.])),\n",
      "                tensor(0.9284)),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([2., 2., 2.]),\n",
      "                 tensor([ 3., -1.]),\n",
      "                 tensor([ 4., -1.])),\n",
      "                tensor(0.9637))],\n",
      "  'loc': [((tensor([1.]), tensor([2., 1.])), tensor(0.9284)),\n",
      "          ((tensor([0.]), tensor([ 3., -1.])), tensor(0.9637))]},\n",
      " {'cart_loc': [((tensor([1.]), tensor([4., 1.])), tensor(0.9637)),\n",
      "               ((tensor([2.]), tensor([ 4., -1.])), tensor(0.9637)),\n",
      "               ((tensor([0.]), tensor([3., 1.])), tensor(0.9300))],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([3., 1.]),\n",
      "                 tensor([2., 1.])),\n",
      "                tensor(0.9284)),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([2., 2., 2.]),\n",
      "                 tensor([3., 0.]),\n",
      "                 tensor([3., 1.])),\n",
      "                tensor(0.9300))],\n",
      "  'loc': [((tensor([1.]), tensor([2., 1.])), tensor(0.9284)),\n",
      "          ((tensor([0.]), tensor([3., 0.])), tensor(0.9300))]})\n"
     ]
    }
   ],
   "source": [
    "robot_locations = [aisles_t[1], aisles_t[2]]\n",
    "cart_locations = [aisles_t[3], front_t[3], back_t[3]]\n",
    "fixed = gen_fixed()\n",
    "start = gen_start()\n",
    "def goal(state):\n",
    "    return any(similarity(loc, aisles_t[3]) > EQ_CUTOFF for (rob, loc), w in state['loc'])\n",
    "\n",
    "pprint(sample(start, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would also like to be able to handle noise in the planning system. Below, we offset the endpoints throughout the adjacency table using a normal distribution with a standard deviation of 5% of the cell. We also offset our robot and cart starting locations by the same distribution, and planning still works. In the real world, this might correspond to a 10cm difference between our perception system's expectation of an object's location, and our navigation system's response to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited 643 states\n",
      "({'cart_loc': [((tensor([0.]), tensor([3.0019, 0.0041])), 1.0),\n",
      "               ((tensor([1.]), tensor([2.9095, 1.0383])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 2.9711, -1.0211])), 1.0)],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([0., 0., 0.]),\n",
      "                 tensor([0.8795, 0.0142]),\n",
      "                 tensor([0.8795, 0.0142])),\n",
      "                1.0),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([0., 0., 0.]),\n",
      "                 tensor([1.9720, 0.0879]),\n",
      "                 tensor([1.9720, 0.0879])),\n",
      "                1.0)],\n",
      "  'loc': [((tensor([0.]), tensor([0.8795, 0.0142])), 1.0),\n",
      "          ((tensor([1.]), tensor([1.9720, 0.0879])), 1.0)]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3.0019, 0.0041])), 1.0),\n",
      "               ((tensor([1.]), tensor([2.9095, 1.0383])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 2.9711, -1.0211])), 1.0)],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([0., 0., 0.]),\n",
      "                 tensor([1.9720, 0.0879]),\n",
      "                 tensor([1.9720, 0.0879])),\n",
      "                1.0),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([ 1.0348, -0.0737]),\n",
      "                 tensor([1.0266, 1.0659])),\n",
      "                tensor(0.8805))],\n",
      "  'loc': [((tensor([1.]), tensor([1.9720, 0.0879])), 1.0),\n",
      "          ((tensor([0.]), tensor([1.0266, 1.0659])), tensor(0.8805))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3.0019, 0.0041])), 1.0),\n",
      "               ((tensor([1.]), tensor([2.9095, 1.0383])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 2.9711, -1.0211])), 1.0)],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([0., 0., 0.]),\n",
      "                 tensor([1.9720, 0.0879]),\n",
      "                 tensor([1.9720, 0.0879])),\n",
      "                1.0),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([0.9862, 0.9283]),\n",
      "                 tensor([2.0579, 0.9634])),\n",
      "                tensor(0.6757))],\n",
      "  'loc': [((tensor([1.]), tensor([1.9720, 0.0879])), 1.0),\n",
      "          ((tensor([0.]), tensor([2.0579, 0.9634])), tensor(0.6757))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3.0019, 0.0041])), 1.0),\n",
      "               ((tensor([1.]), tensor([2.9095, 1.0383])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 2.9711, -1.0211])), 1.0)],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([0.9862, 0.9283]),\n",
      "                 tensor([2.0579, 0.9634])),\n",
      "                tensor(0.6757)),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([1.9449, 0.0432]),\n",
      "                 tensor([ 1.9663, -0.9549])),\n",
      "                tensor(0.9720))],\n",
      "  'loc': [((tensor([0.]), tensor([2.0579, 0.9634])), tensor(0.6757)),\n",
      "          ((tensor([1.]), tensor([ 1.9663, -0.9549])), tensor(0.9720))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3.0019, 0.0041])), 1.0),\n",
      "               ((tensor([1.]), tensor([2.9095, 1.0383])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3.9519, -1.0206])), tensor(0.8999))],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([0.9862, 0.9283]),\n",
      "                 tensor([2.0579, 0.9634])),\n",
      "                tensor(0.6757)),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([2., 2., 2.]),\n",
      "                 tensor([ 3.0419, -1.0274]),\n",
      "                 tensor([ 3.9519, -1.0206])),\n",
      "                tensor(0.8999))],\n",
      "  'loc': [((tensor([0.]), tensor([2.0579, 0.9634])), tensor(0.6757)),\n",
      "          ((tensor([1.]), tensor([ 3.0419, -1.0274])), tensor(0.8999))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3.0019, 0.0041])), 1.0),\n",
      "               ((tensor([1.]), tensor([2.9095, 1.0383])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3.9519, -1.0206])), tensor(0.8999))],\n",
      "  'last_act': [((tensor([0.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([0.9862, 0.9283]),\n",
      "                 tensor([2.0579, 0.9634])),\n",
      "                tensor(0.6757)),\n",
      "               ((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([ 3.0419, -1.0274]),\n",
      "                 tensor([ 1.9865, -1.0412])),\n",
      "                tensor(0.8096))],\n",
      "  'loc': [((tensor([0.]), tensor([2.0579, 0.9634])), tensor(0.6757)),\n",
      "          ((tensor([1.]), tensor([ 1.9865, -1.0412])), tensor(0.8096))]},\n",
      " {'cart_loc': [((tensor([0.]), tensor([3.0019, 0.0041])), 1.0),\n",
      "               ((tensor([2.]), tensor([ 3.9519, -1.0206])), tensor(0.8999)),\n",
      "               ((tensor([1.]), tensor([4.1011, 1.0345])), tensor(0.6214))],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([ 3.0419, -1.0274]),\n",
      "                 tensor([ 1.9865, -1.0412])),\n",
      "                tensor(0.8096)),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([2., 2., 2.]),\n",
      "                 tensor([2.9643, 0.9824]),\n",
      "                 tensor([4.1011, 1.0345])),\n",
      "                tensor(0.6214))],\n",
      "  'loc': [((tensor([1.]), tensor([ 1.9865, -1.0412])), tensor(0.8096)),\n",
      "          ((tensor([0.]), tensor([2.9643, 0.9824])), tensor(0.6214))]},\n",
      " {'cart_loc': [((tensor([2.]), tensor([ 3.9519, -1.0206])), tensor(0.8999)),\n",
      "               ((tensor([1.]), tensor([4.1011, 1.0345])), tensor(0.6214)),\n",
      "               ((tensor([0.]), tensor([ 2.8991, -1.0156])), tensor(0.5400))],\n",
      "  'last_act': [((tensor([1.]),\n",
      "                 tensor([1., 1., 1.]),\n",
      "                 tensor([ 3.0419, -1.0274]),\n",
      "                 tensor([ 1.9865, -1.0412])),\n",
      "                tensor(0.8096)),\n",
      "               ((tensor([0.]),\n",
      "                 tensor([2., 2., 2.]),\n",
      "                 tensor([3.0627, 0.0118]),\n",
      "                 tensor([ 2.8991, -1.0156])),\n",
      "                tensor(0.5400))],\n",
      "  'loc': [((tensor([1.]), tensor([ 1.9865, -1.0412])), tensor(0.8096)),\n",
      "          ((tensor([0.]), tensor([3.0627, 0.0118])), tensor(0.5400))]})\n"
     ]
    }
   ],
   "source": [
    "def noise(length=2):\n",
    "    return 0.05 * torch.randn(length)\n",
    "\n",
    "def gen_fixed():\n",
    "    '''Generate indices for all the fixed tables (just the adjacency table).'''\n",
    "    adjacent = ([(noise() + a, noise() + f) for a, f in zip(aisles_t, front_t)] +\n",
    "                [(noise() + a, noise() + b) for a, b in zip(aisles_t, back_t)] +\n",
    "                [(noise() + front_t[i], noise() + front_t[i+1]) for i in range(len(front_t) - 1)] +\n",
    "                [(noise() + back_t[i], noise() + back_t[i+1]) for i in range(len(back_t) - 1)])\n",
    "    adjacent = adjacent + [(e, s) for s, e in adjacent]\n",
    "    adj_table = [(row, 1.0) for row in adjacent]\n",
    "    return {'adj': [gen_index(adj_table, i) for i in (0, 1)]}\n",
    "\n",
    "robot_locations = [noise() + aisles_t[1], noise() + aisles_t[2]]\n",
    "cart_locations = [noise() + aisles_t[3], noise() + front_t[3], noise() + back_t[3]]\n",
    "fixed = gen_fixed()\n",
    "start = gen_start()\n",
    "pprint(sample(start, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully this notebook makes some of the details of my recent research ideas clear. Thanks for reading all the way to the end! If you have any questions, feel free to email me at kzentner@usc.edu. If you're at USC, I would also be happy to talk with potential collaborators on research topics in this direction. My desk is in the back of RTH 422."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
